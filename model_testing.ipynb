{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn, randn\n",
    "from torch.nn import functional as F\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = randn(3,4,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.3815, -1.0366, -1.3495, -0.5189,  1.0410]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_a = a[0,0:1,:].clone()\n",
    "_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_a[:] = 0\n",
    "_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.3815, -1.0366, -1.3495, -0.5189,  1.0410],\n",
       "        [ 0.1712,  0.9659, -0.5855,  0.5205,  0.0140],\n",
       "        [ 0.3370,  0.0251, -0.0851, -0.2133, -0.1134],\n",
       "        [-1.4340, -0.6931,  0.0771, -1.6478, -0.3585],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([a[0, :, :], _a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = randn(3,4,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.7309, -0.6428, -0.6636,  0.9112, -1.8284],\n",
       "         [ 0.8880,  2.5412,  0.5708,  0.4459, -2.1536],\n",
       "         [ 0.4171,  0.3803,  0.3556, -0.6383,  0.1007],\n",
       "         [ 0.6908,  0.5263,  0.9655, -0.2302,  0.3648]],\n",
       "\n",
       "        [[ 0.2487,  0.3852,  0.1683, -0.3558,  1.5143],\n",
       "         [-0.9058,  0.2830,  0.8163,  0.3340, -0.3418],\n",
       "         [ 0.4614,  1.9832,  0.3731, -1.6793,  1.9163],\n",
       "         [ 1.4766,  0.0780, -0.2949, -1.0389, -0.6695]],\n",
       "\n",
       "        [[ 0.2411, -0.4856,  0.2018, -0.2083,  1.3914],\n",
       "         [ 0.4958, -0.7759, -0.7232,  1.0123, -0.4709],\n",
       "         [-0.2372,  0.4829,  1.8572, -2.7888,  1.5076],\n",
       "         [-0.7266,  0.2925,  1.1517, -0.8410,  1.5142]]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_a = a[:,:,:].clone()\n",
    "_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0.]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_a[:] = 0\n",
    "_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.3815, -1.0366, -1.3495, -0.5189,  1.0410],\n",
       "        [ 0.1712,  0.9659, -0.5855,  0.5205,  0.0140],\n",
       "        [ 0.3370,  0.0251, -0.0851, -0.2133, -0.1134],\n",
       "        [-1.4340, -0.6931,  0.0771, -1.6478, -0.3585],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "torch.cat([a[0, :, :], _a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_class = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.stack([torch.arange(0,10) for _ in range(2)]).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
       "        [0., 1., 2., 3., 4., 5., 6., 7., 8., 9.]])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n",
       "\n",
       "        [[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]]])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def one_hot(T, nb_class, batch_first=True):\n",
    "    assert len(T.unique()) <= nb_class, \"nb_class should be higher then number of unique element in tensor T\"\n",
    "    T_dtype = T.dtype\n",
    "    if not batch_first: T = T.unsqueeze(0)\n",
    "    base_tensor = torch.zeros(T.shape[1])\n",
    "    out = []\n",
    "    for batch in T:\n",
    "        out.append(torch.stack([torch.where(batch == uniq, 1, 0) for uniq in range(nb_class)]).T)\n",
    "    out = torch.stack(out)\n",
    "    if not batch_first: out = out[0]\n",
    "    return out.to(T_dtype)\n",
    "one_hot(a, nb_class, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = randn(30,30,30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.getsizeof(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/processed_data/0.torch\", \"rb\") as f: a = torch.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./test.torch\", \"wb\") as f: torch.save((randn(3,3), randn(3,3)), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.5336, -1.5367, -0.1316],\n",
       "         [-0.1441, -0.5781,  0.2368],\n",
       "         [ 0.4289, -1.7501,  0.3528]]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([torch.tensor([]), randn(1,3,3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = randn(60000, 807, 63)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = randn(3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([1,2,3,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4, 53, 38,  ..., 40, 60, 14],\n",
       "        [35, 28, 30,  ...,  6, 57, 34],\n",
       "        [18, 60, 11,  ..., 41, 37, 55],\n",
       "        ...,\n",
       "        [39, 24, 17,  ..., 38, 12, 38],\n",
       "        [23,  2, 40,  ..., 18, 36, 51],\n",
       "        [ 8, 41, 20,  ..., 39, 12, 12]])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randint(0,61, (16,807))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.Embedding(62, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.one_hot(a, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.randint(0,61,(16,10,))\n",
    "y = F.pad(y, (1,0,0,0), \"constant\", 0)\n",
    "y = F.pad(y, (0,807,0,0), \"constant\", 155)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0, 35, 21, 36, 10,  9,  2, 28, 29,  8, 26,  0, 36, 15, 17, 29, 52,  9,\n",
       "         0, 57, 15, 42,  0,  6, 33, 28, 34, 19, 34, 43, 20, 55,  7,  0, 32, 30,\n",
       "        50, 47, 30, 43, 32, 47, 48, 19,  0, 30, 56, 15, 21, 53, 28, 44, 43, 31,\n",
       "        54,  0, 48, 48, 11, 29,  2, 33, 18, 42,  6, 39,  0, 31, 45, 43,  5, 49,\n",
       "        20, 46, 33,  8,  2,  0,  4, 26, 47, 47, 55,  4, 45, 45, 25, 58,  0, 17,\n",
       "        60, 20, 33, 34, 35, 60, 11, 34,  1,  0, 33,  5, 48, 16, 31, 31, 12, 38,\n",
       "        30, 23,  0, 10, 38, 41,  0, 14, 25, 58, 34,  8, 21,  0, 31,  2,  6, 46,\n",
       "        60, 26, 51, 56, 31, 21,  0,  7, 34,  1, 54, 47, 26, 10, 24, 43, 21,  0,\n",
       "        46, 18, 25, 23, 28, 40, 37, 49, 32, 49,  0, 19, 43, 60, 23, 60, 15, 58,\n",
       "        12, 29,  4,  0, 28, 27, 53, 41,  5, 55, 14, 12, 23, 37])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[torch.where(y == 155, 0, 1).bool()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.stack([torch.arange(0,8) for _ in range(16)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 1, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 1,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 1, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 1, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 1]],\n",
       "\n",
       "        [[1, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 1, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 1,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 1, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 1, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 1]],\n",
       "\n",
       "        [[1, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 1, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 1,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 1, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 1, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 1]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[1, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 1, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 1,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 1, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 1, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 1]],\n",
       "\n",
       "        [[1, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 1, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 1,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 1, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 1, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 1]],\n",
       "\n",
       "        [[1, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 1, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 1,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 1, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 1, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 1]]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.one_hot(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 11, 256])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.Embedding(61,256)(y).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "mha = nn.MultiheadAttention(256, 8, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 807, 256])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = randn(16,807,256)\n",
    "attn_mask = randn(8*16,807,807)\n",
    "mha(x, x, x, attn_mask=attn_mask)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        x_shape,\n",
    "        y_shape,\n",
    "    ):\n",
    "        super(Model, self).__init__()\n",
    "\n",
    "        self.x_shape = x_shape\n",
    "        self.y_shape = y_shape\n",
    "\n",
    "        #Embedding\n",
    "        self.l1 = nn.Linear(self.x_shape[2], 256, False)\n",
    "        self.l2 = nn.Linear(256, 256, False)\n",
    "        \n",
    "        self.pe1 = nn.Parameter(torch.zeros((self.x_shape[1], 256)))\n",
    "        \n",
    "        # Encoder\n",
    "        self.attn1 = nn.MultiheadAttention(256, 64)\n",
    "        \n",
    "        self.l4 = nn.Linear(256, 256)\n",
    "        self.l3 = nn.Linear(256, 256)\n",
    "        self.l5 = nn.Linear(256, 256)\n",
    "        self.l6 = nn.Linear(256, 256)\n",
    "        \n",
    "        # Decoder\n",
    "        self.attn2 = nn.MultiheadAttention(256, 64)\n",
    "        \n",
    "        self.l7 = nn.Linear(256, 256)\n",
    "        self.l8 = nn.Linear(256, 256)\n",
    "        self.l9 = nn.Linear(256, 256)\n",
    "        self.l10 = nn.Linear(256, 256)\n",
    "        \n",
    "        # Classifier\n",
    "        self.l11 = nn.Linear(256, self.y_shape[2])\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        #Embedding\n",
    "        x = self.l1(x)\n",
    "        x = F.gelu(x)\n",
    "        x = self.l2(x)\n",
    "        \n",
    "        #x = x + self.pe1\n",
    "        \n",
    "        # Encoder\n",
    "        x, _ = self.attn1(x, x, x)\n",
    "        \n",
    "        x = self.l3(x)\n",
    "        x = F.gelu(x)\n",
    "        x = self.l4(x)\n",
    "        x = self.l5(x)\n",
    "        x = F.gelu(x)\n",
    "        x = self.l6(x)\n",
    "        \n",
    "        # Decoder\n",
    "        x, _ = self.attn2(x, x, x)\n",
    "        \n",
    "        x = self.l7(x)\n",
    "        x = F.gelu(x)\n",
    "        x = self.l8(x)\n",
    "        x = self.l9(x)\n",
    "        x = F.gelu(x)\n",
    "        x = self.l10(x)\n",
    "        \n",
    "        # Classifier\n",
    "        x = x[:,:self.y_shape[1],:]\n",
    "        \n",
    "        x = self.l11(x)\n",
    "        x = F.softmax(x, 1)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 43, 59])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model([1,807,63], [1,43,59])\n",
    "x = model(randn(1,807,63))\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Transformer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.1646, -0.3673,  2.4507,  ..., -0.6352, -1.0502,  0.4277],\n",
       "         [-1.1142, -0.4135,  0.3524,  ...,  0.2965, -0.8126, -0.2754],\n",
       "         [ 1.4338,  1.1891,  0.1754,  ..., -0.5571, -1.0016,  0.5825],\n",
       "         ...,\n",
       "         [ 0.5385, -1.5545,  0.1536,  ...,  1.6781, -1.1260, -0.8971],\n",
       "         [ 1.2013,  0.2258,  0.9249,  ..., -0.3320,  0.1370,  0.2925],\n",
       "         [ 0.9452,  0.7171,  1.1200,  ...,  0.5412,  0.4270,  0.2423]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(randn(1,64,512), randn(1,64,512))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
